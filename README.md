# Master's Thesis - Detecting Unconscious Bias and Discrimination in Algorithms

## Abstract
This thesis is intended to introduce and better understand the concepts of bias and fairness of algorithms, and to review open-source tools available online to facilitate bias detection and encourage companies and individuals to audit their algorithms for the presence of discrimination against some protected groups.

The methodology includes the literature review to search for different definitions of fairness and to understand the importance and prevalence of discrimination in algorithms. Secondly, an exploratory analysis with visualizations is conducted for the COMPAS algorithm dataset, which is then used to generate bias and fairness reports using two open-source bias detection tools â€“ Aequitas and What-If Tool.

Concerning the results and conclusions, firstly, the set of different definitions of fairness and their applications proves that one standardized perception of fairness does not exist, and it usually becomes an ethical question on how to interpret it. Secondly, the results of the analysis confirm the presence of racial and gender bias in the COMPAS algorithm. However, the focus is mostly on presenting the capabilities of the chosen tools, which offer a broad range of interesting visualizations and reports, and considerably facilitate detecting and understanding where bias can exist in the data or the machine learning model. Such tools are essential to think about bias detection as the standard process of building models in companies and monitoring their performance afterward. Nonetheless, auditing algorithms is just one step in the process of mitigating and eradicating discrimination from them. Joint efforts and further work are required to make it a common practice.
